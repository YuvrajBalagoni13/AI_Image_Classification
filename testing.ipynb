{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n",
      "0.21.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as Timer\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset, DataLoader, ConcatDataset, Dataset\n",
    "from torchinfo import summary\n",
    "import wandb\n",
    "import onnx\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from Scripts import engine\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/\")\n",
    "image_path = data_path/\"CIFAKE\"\n",
    "\n",
    "def walk_trough_dir(dir_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories & {len(filenames)} images in {dirpath}.\")\n",
    "\n",
    "walk_trough_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Dataset URL: https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mScripts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m download_data\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train_dir, test_dir = \u001b[43mdownload_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\Scripts\\download_data.py:17\u001b[39m, in \u001b[36mdownload_data\u001b[39m\u001b[34m(data_URL)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDownloading data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[43mod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_URL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m train_dir = image_path/ \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m test_dir = image_path/ \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\opendatasets\\__init__.py:13\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(dataset_id_or_url, data_dir, force, dry_run, **kwargs)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload\u001b[39m(dataset_id_or_url, data_dir=\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m, force=\u001b[38;5;28;01mFalse\u001b[39;00m, dry_run=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs):\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Check for a Kaggle dataset URL\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_kaggle_url(dataset_id_or_url):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdownload_kaggle_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_id_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Check for Google Drive URL\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_google_drive_url(dataset_id_or_url):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\opendatasets\\utils\\kaggle_api.py:65\u001b[39m, in \u001b[36mdownload_kaggle_dataset\u001b[39m\u001b[34m(dataset_url, data_dir, force, dry_run)\u001b[39m\n\u001b[32m     63\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mCould not delete zip file, got\u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m         \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_download_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43munzip\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mThis is a dry run, skipping..\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py:1657\u001b[39m, in \u001b[36mKaggleApi.dataset_download_files\u001b[39m\u001b[34m(self, dataset, path, force, quiet, unzip, licenses)\u001b[39m\n\u001b[32m   1655\u001b[39m   request.dataset_slug = dataset_slug\n\u001b[32m   1656\u001b[39m   request.dataset_version_number = dataset_version_number\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m   response = \u001b[43mkaggle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1659\u001b[39m outfile = os.path.join(effective_path, dataset_slug + \u001b[33m'\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1660\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.download_needed(response, outfile, quiet):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\kagglesdk\\datasets\\services\\dataset_api_service.py:80\u001b[39m, in \u001b[36mDatasetApiClient.download_dataset\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m   request = ApiDownloadDatasetRequest()\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatasets.DatasetApiService\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mApiDownloadDataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHttpRedirect\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\kagglesdk\\kaggle_http_client.py:102\u001b[39m, in \u001b[36mKaggleHttpClient.call\u001b[39m\u001b[34m(self, service_name, request_name, request, response_type)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mself\u001b[39m._init_session()\n\u001b[32m    100\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._prepare_request(service_name, request_name, request)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m http_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m response = \u001b[38;5;28mself\u001b[39m._prepare_response(response_type, http_response)\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\requests\\sessions.py:724\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[32m    722\u001b[39m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[32m    723\u001b[39m     gen = \u001b[38;5;28mself\u001b[39m.resolve_redirects(r, request, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     history = \u001b[43m[\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    726\u001b[39m     history = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\requests\\sessions.py:265\u001b[39m, in \u001b[36mSessionRedirectMixin.resolve_redirects\u001b[39m\u001b[34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[39m\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m.cookies, prepared_request, resp.raw)\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\urllib3\\response.py:1066\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1064\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1069\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\urllib3\\response.py:955\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    957\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\urllib3\\response.py:879\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    876\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    882\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    888\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    889\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\YUVRAJ\\ML\\Projects_end-to-end\\AI_image_classifier\\venv\\Lib\\site-packages\\urllib3\\response.py:862\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1253\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1251\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1252\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1107\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from Scripts import download_data\n",
    "\n",
    "train_dir, test_dir = download_data.download_data(\"https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = image_path/\"train\"\n",
    "test_dir = image_path/\"test\"\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "random_image_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "random_img_path = random.choice(random_image_list)\n",
    "image_class = random_img_path.parent.stem\n",
    "random_img = Image.open(random_img_path)\n",
    "\n",
    "print(image_class)\n",
    "random_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomResizedCrop((224, 224), scale=(0.1,1)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_transforms = {\n",
    "    \"No_Augmentation\" : transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.RandomResizedCrop((224,224), scale = (0.1, 1)),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    \"Gaussian_Blur\" : transforms.Compose([\n",
    "        transforms.RandomApply([\n",
    "            transforms.GaussianBlur(kernel_size= 3, sigma= (0.1, 0.3))\n",
    "        ], p= 0.5),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_image = transform(random_img)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(transformed_image.permute(1,2,0))\n",
    "plt.title(f\"Image class : {image_class} & shape : {transformed_image.shape}\")\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"FAKE\", \"REAL\"]\n",
    "class_dict = {\"FAKE\": 0,\n",
    "              \"REAL\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root = train_dir,\n",
    "                                  transform= transform,\n",
    "                                  target_transform= None)\n",
    "test_data = datasets.ImageFolder(root = test_dir,\n",
    "                                 transform= test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.randint(0, 20000)\n",
    "plt.imshow(test_data[random_idx][0].permute(1,2,0))\n",
    "plt.title(f\"Image class: {class_names[test_data[random_idx][1]]} & Image shape : {test_data[random_idx][0].permute(1,2,0).shape}\")\n",
    "plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = list(range(0, 1250))\n",
    "len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = list(range(50000, 51250))\n",
    "len(ss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset(dataset, num_of_datasets, size_of_datasets):\n",
    "    \"\"\"\n",
    "    This will create n no. of subsets of the given data\n",
    "\n",
    "    Args:\n",
    "        dataset: The original dataset.\n",
    "        num_subsets: Number of subsets to create.\n",
    "        subset_size: Number of samples in each subset.\n",
    "    \n",
    "    Returns:\n",
    "        A list of Subset objects.\n",
    "    \"\"\"\n",
    "    subsets = []\n",
    "    for i in range(num_of_datasets):\n",
    "        start_idx = i * int(size_of_datasets / 2) \n",
    "        end_idx = start_idx + int(size_of_datasets / 2)\n",
    "\n",
    "        start_idx_2 = start_idx + int(len(dataset) / 2)\n",
    "        end_idx_2 = end_idx + int(len(dataset) / 2)\n",
    "\n",
    "        subset_indices_1 = list(range(start_idx, end_idx))\n",
    "        subset_indices_2 = list(range(start_idx_2, end_idx_2))\n",
    "        subset_indices = subset_indices_1 + subset_indices_2\n",
    "        random.shuffle(subset_indices)\n",
    "        \n",
    "        subsets.append(Subset(dataset, subset_indices))\n",
    "\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = create_subset(train_data, 40, 2500)\n",
    "test_subset = create_subset(test_data, 40, 500)\n",
    "\n",
    "img, label = next(iter(test_subset[0]))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_subset), len(train_subset[0]),len(train_subset[0][0]), len(train_subset[0][0][0]), len(train_subset[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "train_dataloader_subsets = [DataLoader(subset, BATCH_SIZE, shuffle= True) for subset in train_subset]\n",
    "test_dataloader_subsets = [DataLoader(subset, BATCH_SIZE) for subset in test_subset]\n",
    "\n",
    "train_dataloader_subsets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, (img, label) in enumerate(test_dataloader_subsets[0]):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test_dataloader_subsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "fig.suptitle(\"Batch Images\", fontsize=32)\n",
    "rows, columns = 5, 10\n",
    "for batch_idx, (img, label) in enumerate(test_dataloader_subsets[0]):\n",
    "    if (batch_idx < 1):\n",
    "        for i in range(1, rows * columns + 1):\n",
    "            fig.add_subplot(rows, columns, i)\n",
    "            plt.imshow(img[i-1].permute(1,2,0))\n",
    "            plt.title(class_names[int(label[i-1])], fontsize=12)\n",
    "            plt.axis(False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"efficientnet_b0\"\n",
    "model_weights_name  = \"EfficientNet_B0_Weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = getattr(torchvision.models, model_name)\n",
    "\n",
    "model_weights = getattr(torchvision.models, model_weights_name).DEFAULT\n",
    "\n",
    "model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientb0_model = torchvision.models.efficientnet_b0(weights= model_weights).to(device)\n",
    "efficientb0_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = getattr(torchvision.models, model_name)\n",
    "model = resnet_model(weights = model_weights).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [name for name, param in model.named_parameters() if param.requires_grad and \"weight\" in name]\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = getattr(model, layers[-1][: -9])\n",
    "sequence.out_features = 2\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model= efficientb0_model,\n",
    "        input_size= (25,3,224,224),\n",
    "        col_names= [\"input_size\", \"output_size\",\"num_params\", \"trainable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientb0_model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in efficientb0_model.features[:-3].parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "efficientb0_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p = 0.2, inplace= True),\n",
    "    nn.Linear(in_features=1280, out_features= 2, bias= True)\n",
    ")\n",
    "\n",
    "summary(model= efficientb0_model,\n",
    "        input_size= (25,3,224,224),\n",
    "        col_names= [\"input_size\", \"output_size\",\"num_params\", \"trainable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# Combine iterators from both DataLoaders\n",
    "combined_iterator = chain(iter(test_dataloader_subsets[0]), iter(test_dataloader_subsets[1]), iter(test_dataloader_subsets[2]), iter(test_dataloader_subsets[3]))\n",
    "\n",
    "for batch, (img, label) in enumerate(combined_iterator):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    iterator = chain(iter(iterator),iter(test_dataloader_subsets[i]))\n",
    "for batch, (img, label) in enumerate(iterator):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class empty_dataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return 0\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return IndexError(\"This dataset is empty!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Dataset URL: https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od \n",
    " \n",
    "dataset = \"https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\"\n",
    "od.download(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cifake-real-and-ai-generated-synthetic-images'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(\"https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\")\n",
    "path = parsed_url.path\n",
    "data_dir = path.split('/')[-1]\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\CIFAKE directory exists\n",
      "Downloading data...\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadZipFile\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDownloading data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m     f.write(request.content)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcifake-real-and-ai-generated-synthetic-images.zip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUnzipping  data...\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m     20\u001b[39m     zip_ref.extractall(image_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1339\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1339\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1341\u001b[39m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[32m   1342\u001b[39m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[32m   1343\u001b[39m         \u001b[38;5;28mself\u001b[39m._didModify = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\zipfile\\__init__.py:1406\u001b[39m, in \u001b[36mZipFile._RealGetContents\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1404\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[32m-> \u001b[39m\u001b[32m1406\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[33m\"\u001b[39m\u001b[33mFile is not a zip file\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1407\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.debug > \u001b[32m1\u001b[39m:\n\u001b[32m   1408\u001b[39m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[31mBadZipFile\u001b[39m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"CIFAKE\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists\")\n",
    "else:\n",
    "    print(f\"Creating {image_path} directory...\")\n",
    "    image_path.mkdir(parents= True, exist_ok= True)\n",
    "\n",
    "with open(data_path / \"cifake-real-and-ai-generated-synthetic-images.zip\", \"wb\") as f:\n",
    "    request = requests.get(\"https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images/cifake-real-and-ai-generated-synthetic-images.zip\")\n",
    "    print(\"Downloading data...\")\n",
    "    f.write(request.content)\n",
    "\n",
    "with zipfile.ZipFile(data_path / \"cifake-real-and-ai-generated-synthetic-images.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping  data...\") \n",
    "    zip_ref.extractall(image_path)\n",
    "\n",
    "os.remove(data_path / \"cifake-real-and-ai-generated-synthetic-images.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Trainable\n",
       "===========================================================================================================================================================\n",
       "EfficientNet                                            [25, 3, 224, 224]         [25, 2]                   --                        Partial\n",
       "├─Sequential: 1-1                                       [25, 3, 224, 224]         [25, 1280, 7, 7]          --                        Partial\n",
       "│    └─Conv2dNormActivation: 2-1                        [25, 3, 224, 224]         [25, 32, 112, 112]        --                        False\n",
       "│    │    └─Conv2d: 3-1                                 [25, 3, 224, 224]         [25, 32, 112, 112]        (864)                     False\n",
       "│    │    └─BatchNorm2d: 3-2                            [25, 32, 112, 112]        [25, 32, 112, 112]        (64)                      False\n",
       "│    │    └─SiLU: 3-3                                   [25, 32, 112, 112]        [25, 32, 112, 112]        --                        --\n",
       "│    └─Sequential: 2-2                                  [25, 32, 112, 112]        [25, 16, 112, 112]        --                        False\n",
       "│    │    └─MBConv: 3-4                                 [25, 32, 112, 112]        [25, 16, 112, 112]        (1,448)                   False\n",
       "│    └─Sequential: 2-3                                  [25, 16, 112, 112]        [25, 24, 56, 56]          --                        False\n",
       "│    │    └─MBConv: 3-5                                 [25, 16, 112, 112]        [25, 24, 56, 56]          (6,004)                   False\n",
       "│    │    └─MBConv: 3-6                                 [25, 24, 56, 56]          [25, 24, 56, 56]          (10,710)                  False\n",
       "│    └─Sequential: 2-4                                  [25, 24, 56, 56]          [25, 40, 28, 28]          --                        False\n",
       "│    │    └─MBConv: 3-7                                 [25, 24, 56, 56]          [25, 40, 28, 28]          (15,350)                  False\n",
       "│    │    └─MBConv: 3-8                                 [25, 40, 28, 28]          [25, 40, 28, 28]          (31,290)                  False\n",
       "│    └─Sequential: 2-5                                  [25, 40, 28, 28]          [25, 80, 14, 14]          --                        False\n",
       "│    │    └─MBConv: 3-9                                 [25, 40, 28, 28]          [25, 80, 14, 14]          (37,130)                  False\n",
       "│    │    └─MBConv: 3-10                                [25, 80, 14, 14]          [25, 80, 14, 14]          (102,900)                 False\n",
       "│    │    └─MBConv: 3-11                                [25, 80, 14, 14]          [25, 80, 14, 14]          (102,900)                 False\n",
       "│    └─Sequential: 2-6                                  [25, 80, 14, 14]          [25, 112, 14, 14]         --                        False\n",
       "│    │    └─MBConv: 3-12                                [25, 80, 14, 14]          [25, 112, 14, 14]         (126,004)                 False\n",
       "│    │    └─MBConv: 3-13                                [25, 112, 14, 14]         [25, 112, 14, 14]         (208,572)                 False\n",
       "│    │    └─MBConv: 3-14                                [25, 112, 14, 14]         [25, 112, 14, 14]         (208,572)                 False\n",
       "│    └─Sequential: 2-7                                  [25, 112, 14, 14]         [25, 192, 7, 7]           --                        False\n",
       "│    │    └─MBConv: 3-15                                [25, 112, 14, 14]         [25, 192, 7, 7]           (262,492)                 False\n",
       "│    │    └─MBConv: 3-16                                [25, 192, 7, 7]           [25, 192, 7, 7]           (587,952)                 False\n",
       "│    │    └─MBConv: 3-17                                [25, 192, 7, 7]           [25, 192, 7, 7]           (587,952)                 False\n",
       "│    │    └─MBConv: 3-18                                [25, 192, 7, 7]           [25, 192, 7, 7]           (587,952)                 False\n",
       "│    └─Sequential: 2-8                                  [25, 192, 7, 7]           [25, 320, 7, 7]           --                        False\n",
       "│    │    └─MBConv: 3-19                                [25, 192, 7, 7]           [25, 320, 7, 7]           (717,232)                 False\n",
       "│    └─Conv2dNormActivation: 2-9                        [25, 320, 7, 7]           [25, 1280, 7, 7]          --                        True\n",
       "│    │    └─Conv2d: 3-20                                [25, 320, 7, 7]           [25, 1280, 7, 7]          409,600                   True\n",
       "│    │    └─BatchNorm2d: 3-21                           [25, 1280, 7, 7]          [25, 1280, 7, 7]          2,560                     True\n",
       "│    │    └─SiLU: 3-22                                  [25, 1280, 7, 7]          [25, 1280, 7, 7]          --                        --\n",
       "├─AdaptiveAvgPool2d: 1-2                                [25, 1280, 7, 7]          [25, 1280, 1, 1]          --                        --\n",
       "├─Sequential: 1-3                                       [25, 1280]                [25, 2]                   --                        True\n",
       "│    └─Dropout: 2-10                                    [25, 1280]                [25, 1280]                --                        --\n",
       "│    └─Linear: 2-11                                     [25, 1280]                [25, 2]                   2,562                     True\n",
       "===========================================================================================================================================================\n",
       "Total params: 4,010,110\n",
       "Trainable params: 414,722\n",
       "Non-trainable params: 3,595,388\n",
       "Total mult-adds (Units.GIGABYTES): 9.61\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 15.05\n",
       "Forward/backward pass size (MB): 2696.95\n",
       "Params size (MB): 16.04\n",
       "Estimated Total Size (MB): 2728.04\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Scripts import model\n",
    "\n",
    "effnet_model = model.model_builder(model_weights=\"EfficientNet_B0_Weights\",\n",
    "                                     model_name= \"efficientnet_b0\",\n",
    "                                     unfreeze_layers=3,\n",
    "                                     num_classes= 2,\n",
    "                                     layer_name= \"classifier\",\n",
    "                                     device= device)\n",
    "\n",
    "summary(model= effnet_model,\n",
    "        input_size= (25,3,224,224),\n",
    "        col_names= [\"input_size\", \"output_size\",\"num_params\", \"trainable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False),\n",
       " BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False),\n",
       " BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False),\n",
       " BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False),\n",
       " BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False),\n",
       " BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False),\n",
       " BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False),\n",
       " BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False),\n",
       " BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False),\n",
       " BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False),\n",
       " BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False),\n",
       " BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False),\n",
       " BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False),\n",
       " BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False),\n",
       " BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False),\n",
       " BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False),\n",
       " BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1)),\n",
       " Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Linear(in_features=1280, out_features=2, bias=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_modules = [\n",
    "        module for module in effnet_model.modules() if not list(module.children()) and list(module.parameters())  \n",
    "    ]\n",
    "leaf_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0277,  0.0010,  0.0216,  ...,  0.0068,  0.0229, -0.0169],\n",
       "         [ 0.0093,  0.0132, -0.0184,  ..., -0.0279,  0.0126,  0.0270]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([5.9206e-05, 1.6641e-02], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "data1 = []\n",
    "for layer in leaf_modules[::-1][1:3]:\n",
    "    for param in layer.parameters():\n",
    "        data.append(param)\n",
    "\n",
    "for param in leaf_modules[::-1][0].parameters():\n",
    "    data1.append(param)\n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    weight_decay: 0.0001\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.0001\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": data1, \"lr\": 0.01},\n",
    "    {\"params\": data, \"lr\": 0.001}\n",
    "], weight_decay= 1e-4)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amount_of_data(dataloader_subsets,\n",
    "                   multiple,\n",
    "                   batch_size):\n",
    "    total_subsets = len(dataloader_subsets)\n",
    "\n",
    "    concatdataset = empty_dataset()\n",
    "    \n",
    "    if multiple > total_subsets:\n",
    "        raise ValueError(\n",
    "            \"multiple greater than the number of subsets\"\n",
    "        )\n",
    "    else:\n",
    "        for i in range(multiple):\n",
    "            dataloader_dataset = dataloader_subsets[i].dataset\n",
    "            concatdataset = ConcatDataset([concatdataset, dataloader_dataset])\n",
    "        dataloaders = DataLoader(concatdataset, batch_size= batch_size, shuffle= True)\n",
    "        \n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader_subsets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_2_dataloader = amount_of_data(test_dataloader_subsets, 2, 50)\n",
    "len(subset_2_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    weight_decay: 0.0001\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0.0001\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "        {\"params\": effnet_model.classifier.parameters(), \"lr\" : 0.01},\n",
    "        {\"params\": effnet_model.features[-2:].parameters(), \"lr\" : 0.001}\n",
    "    ], weight_decay= 1e-4)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=\"AI_Image_Classification\", name=\"50_0.01-0.001_10_subs_2_last_3_layer_unfreeze\", settings=wandb.Settings(symlink=False)) as run:\n",
    "    learning_rate_classifier = 0.01\n",
    "    learning_rate_unfrozenlayer = 0.001\n",
    "    batch_size = 50\n",
    "    epochs = 10\n",
    "    subsetdata_amount = 2\n",
    "\n",
    "    run.config.learning_rate = learning_rate_classifier\n",
    "    run.config.learning_rate_unfrozenlayer = learning_rate_unfrozenlayer\n",
    "    run.config.batch_size = batch_size\n",
    "    run.config.epochs = epochs\n",
    "    run.config.subsetdata_amount = subsetdata_amount\n",
    "    run.config.ARCHITECHTURE = \"EfficientNet_B0_unfreezed_last_3_layer\"\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {\"params\": efficientb0_model.classifier.parameters(), \"lr\" : learning_rate_classifier},\n",
    "        {\"params\": efficientb0_model.features[-2:].parameters(), \"lr\" : learning_rate_unfrozenlayer}\n",
    "    ], weight_decay= 1e-4)\n",
    "\n",
    "    results = { \n",
    "            \"train loss\": [],\n",
    "            \"train acc\": [],\n",
    "            \"test loss\": [],\n",
    "            \"test acc\": []\n",
    "        }\n",
    "    \n",
    "    train_subsetdata_amount_dataloader = amount_of_data(train_dataloader_subsets, subsetdata_amount, batch_size)\n",
    "    test_subsetdata_amount_dataloader = amount_of_data(test_dataloader_subsets, subsetdata_amount, batch_size)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        # Training Loop\n",
    "        train_loss, train_acc, y_train_actual, y_train_predicted = engine.train_loop(model= efficientb0_model,\n",
    "                                                                                     train_dataloader= train_subsetdata_amount_dataloader,\n",
    "                                                                                     loss_fn= loss_fn,\n",
    "                                                                                     optimizer= optimizer,\n",
    "                                                                                     device= device)\n",
    "        \n",
    "\n",
    "        # Testing Loop\n",
    "        test_loss, test_acc, y_test_actual, y_test_predicted = engine.test_loop(model= efficientb0_model,\n",
    "                                                                                test_dataloader= test_subsetdata_amount_dataloader,\n",
    "                                                                                loss_fn= loss_fn,\n",
    "                                                                                device= device)\n",
    "\n",
    "        results[\"train loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
    "        results[\"train acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
    "        results[\"test loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
    "        results[\"test acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
    "\n",
    "        run.log({\n",
    "            \"epoch\" : epoch + 1,\n",
    "            \"train_loss\" : train_loss,\n",
    "            \"train_accuracy\" : train_acc,\n",
    "            \"test_loss\" : test_loss,\n",
    "            \"test_accuracy\" : test_acc,\n",
    "        })\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}: train loss: {train_loss:.4f} |\\ntrain accuracy: {train_acc:.4f} |\\ntest loss: {test_loss:.4f} |\\ntest accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        torch.onnx.export(\n",
    "            efficientb0_model,\n",
    "            torch.randn(1,3,224,224),\n",
    "            \"efficientnetb0.onnx\",\n",
    "            input_names = [\"input\"],\n",
    "            output_names = [\"output\"],\n",
    "        )\n",
    "    \n",
    "    run.log_artifact(\"efficientnetb0.onnx\", name= \"50_0.01-0.001_10_subs_2_last_3_layer_unfreeze\", type= \"model\")\n",
    "\n",
    "    print(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_train_actual, y_train_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test_actual, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test_actual, y_test_predicted, output_dict= True)\n",
    "cr[\"0\"][\"recall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train_actual, y_train_predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test_actual, y_test_predicted)\n",
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(cm_test, display_labels= class_names)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts import datapreprocess\n",
    "\n",
    "preprocess = datapreprocess.DataPreprocessor(train_dir, test_dir)\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = preprocess.Build_Dataloaders(train_augmentation= \"No_Augmentation\",\n",
    "                                                         test_augmentation= \"No_Augmentation\",\n",
    "                                                         num_subsets= 40,\n",
    "                                                         batch_size= 50,\n",
    "                                                         percentage_data= 20)\n",
    "\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
